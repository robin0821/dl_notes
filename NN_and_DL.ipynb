{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">ONE: Deep Learning and its building blocks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Main drivers of DL</h2>\n",
    "\n",
    "* Amount of data  \n",
    "* Performance (Computation)  \n",
    "* Algorithms innovations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\"> Activation Functions </h2>  \n",
    "\n",
    "1. **Sigmoid**  \n",
    "$$ a = \\sigma(\\mathcal{Z}) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-\\mathcal{Z}} } = \\frac{e^\\mathcal{Z}}{e^\\mathcal{Z} + 1}, \\textrm{where } \\mathcal{Z} = W^T + b \\tag{1a}$$\n",
    "\n",
    "<img src='./img/sigmoid_function.png' style=\"width:300px;height:150px\">\n",
    "\n",
    "_The derivative of Sigmoid function:_\n",
    "\n",
    "$$ \\frac{\\partial a}{\\partial Z}=\\frac{d}{dZ}g(Z) =\\frac{1}{1+e^{-Z}}\\left(1-\\frac{1}{1+e^{-Z}} \\right) = a(1-a)=g(Z)\\large(\\small 1-g(Z)\\large)  \\tag{1d}$$\n",
    "\n",
    "$$dw = d(Z)X$$\n",
    "\n",
    "2. **Relu**  \n",
    "$$ a = max(0, \\mathcal{Z}), \\textrm{where } \\mathcal{Z}=W^T + b \\tag{2a}$$\n",
    "\n",
    "<img src='./img/relu_function.png' style=\"width:300px;height:150px\">\n",
    "\n",
    "_The derivative of Relu function:_  \n",
    "$$ g'(Z) = \\begin{cases}0 \\mbox{ if Z<0} \\\\1 \\mbox{ if Z>0}\\\\undefined \\mbox{ if Z=0} \\end{cases} \\tag{2d}$$\n",
    "\n",
    "3. **Leaky Relu**  \n",
    "$$ a = max(0.01\\mathcal{Z}, \\mathcal{z})=\\begin{cases} \\mathcal{Z} \\mbox{ , if } Z > 0\\\\ \\mathcal{0.01Z} \\mbox{ , if }Z<=0\\end{cases} \\tag{3a}$$\n",
    "\n",
    "<img src='./img/leaky_relu_function.png' style=\"width:300px;height:150px\">\n",
    "\n",
    "_The derivative of Leaky Relu function:_  \n",
    "$$ g'(Z) = \\begin{cases}0.01 \\mbox{  if Z<0} \\\\1 \\mbox{  if Z>0} \\end{cases} $$\n",
    "\n",
    "4. **Tanh**  \n",
    "$$ a = \\tanh({\\mathcal{Z}}) = \\frac{e^{\\mathcal{Z}} - e^{\\mathcal{Z}}}{e^{\\mathcal{Z}} + e^{\\mathcal{Z}}} \\tag{4a}$$\n",
    "\n",
    "<img src='./img/tanh_function.gif' style=\"width:300px;height:150px\">\n",
    "\n",
    "_The derivative of Tanh function:_  \n",
    "$$ g'(Z) = \\frac{d}{dZ}g(Z) = 1-{\\tanh(z)}^2 \\tag{4d}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\"> Loss & Cost Functions</h2>\n",
    "\n",
    "**1. Logistic Regression cost function**\n",
    " - Loss (error) function: the error for a single training example  \n",
    "$$ \\mathcal{L}(\\hat{y}, y) = -\\large \\left( \\small y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})\\large \\right) \\tag{1e}$$\n",
    " - Cost function: the average of the loss functions of the entire training set  \n",
    "$$ \\mathcal{J}(w, b) = \\frac{1}{m}\\sum_{i=1}^m \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)}) \\tag{1c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\"> Algorithms (Models) </h2>\n",
    "\n",
    "#### 1. Logistic Regression  \n",
    "<img src='./img/LogReg_kiank.png' style=\"width:600px;heigth:300px\">$\\tag{1m}$  \n",
    "\n",
    "**Mathmatically:**  \n",
    "For one example $ x^{(i)}$:  \n",
    "$$ z^{(i)} = w_0 x_0^{(i)} + w_1 x_1^{(i)} + ... + w_{12286} x_{12286}^{(i)} + w_{12287} x_{12287}^{(i)} + b \\tag{1}$$ \n",
    "\n",
    "The vectorized execution is as follows:   \n",
    "$$\\begin{bmatrix}\n",
    "z^{(1)} & z^{(2)} & ... & z^{(m)}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "w_0 & w_1 & ... & w_{12286} & w_{12287}\n",
    "\\end{bmatrix} \\times \n",
    "\\begin{bmatrix}\n",
    "x_0^{(1)} & x_0^{(2)} & ... & x_0^{(m)} \\\\\n",
    "x_1^{(1)} & x_1^{(2)} & ... & x_1^{(m)} \\\\\n",
    "& .............. \\\\\n",
    "x_{12286}^{(1)} & x_{12286}^{(2)} & ... & x_{12286}^{(m)} \\\\\n",
    "x_{12287}^{(1)} & x_{12287}^{(2)} & ... & x_{12287}^{(m)} \\\\\n",
    "\\end{bmatrix} + b \\tag{2}$$\n",
    "\n",
    "\n",
    "#### 2. General Representation of Neural Network (NN) \n",
    "<img src='./img/classification_kiank.png' style=\"width:600px;height:300px;\"> $ \\tag{2m}$\n",
    "\n",
    "**Mathmatically:**  \n",
    "For one example $ x^{(i)} $:\n",
    "$$ z^{[1](i)} = W^{[1]}x^{(i)} + b^{[1]} \\tag{#1 Linear Function} $$\n",
    "$$ a^{[1](i)} = \\tanh(z^{[1](i)}) \\tag{#1 Activation}$$\n",
    "$$ z^{[2](i)} = W^{[2]}a^{[1](i)} + b^{[2]} \\tag{#2 Linear Function}$$\n",
    "$$ \\hat{y}^{(i)} = a^{[2](i)} = \\sigma(z^{[2](i)}) \\tag{#2 Activation}$$\n",
    "$$ y^{(i)}_{prediction} = \\begin{cases} 1& \\mbox{if } a^{[2](i)} > 0.5 \\\\0& \\textrm{otherwise} \\end{cases} \\tag{output}$$\n",
    "Cost function $J$ as follows:\n",
    "$$ J = -\\frac{1}{m} \\sum_{i=0}^m \\large\\left( \\small y^{(i)}\\log\\left(a^{[2](i)}\\right) + (1-y^{(i)}\\log\\left(1-a^{[2](i)} \\right) \\large\\right)$$\n",
    "\n",
    "#### 2. AlexNet  \n",
    "\n",
    "#### 3. VGG-16  \n",
    "\n",
    "#### 4. Inception  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\"> Get the matrix dimension right!!! </h2>\n",
    "\n",
    "_for parameters:_  \n",
    "$ W^{[l]}: (n^{[l]}, n^{l-1}) \\mbox{,  } b^{[l]}: (n^{[l]} ,1)$  \n",
    "$ dw^{[l]}: (n^{[l]}, n^{l-1}) \\mbox{,  } db^{[l]}: (n^{[l]} ,1) $\n",
    "\n",
    "_vectorized implementation:_  \n",
    "$ Z^{[l]}, A^{[l]}: (n^{[l]}, m)$  \n",
    "$ dZ^{[l]}, dA^{[l]}: (n^{[l]}, m)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\"> Forward propagation and backward propagation </h2>  \n",
    "\n",
    "<img src=\"./img/final_outline.png\">\n",
    "<center>**The overall structure**</center>\n",
    "\n",
    "<img src=\"./img/backpass.png\">\n",
    "<center>**The backprop**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">TWO: CNN - Convolutional Neural Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">THREE: RNN - Recurrent Neural Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Four: Improving DL network - Hyperparameter tuning, Regularization and Optimization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">FIVE: Stucturing ML projects</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">SIX: Appendix</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Terminology</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RELU**: *Rectified Linear Unit*  \n",
    "**CNN**: *Convolutional Neural Network*  \n",
    "**RNN**: *Recurrent Neural Network*  \n",
    "**ROC**: *Receiver Operation Characteristics*  \n",
    "**AUC**: *Aread Under the Curve*  \n",
    "**Activation**:  \n",
    "**Gradient Descent**:   \n",
    "**Convex**:  \n",
    "**Computation Graph**:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Notation</h2>  \n",
    "\n",
    "**General comments**  \n",
    "Superscript (i) will denote the $i^{th}$ training example while superscript [l] will denote the $l^{th}$ layer  \n",
    "\n",
    "**Sizes**  \n",
    "$ m $: number of examples in the dataset  \n",
    "$ n_x $: input size (dataset size)  \n",
    "$ n_y $: output size  \n",
    "$ n_h^{[l]} $: number of hidden units of the $ l^{th}$ layer  \n",
    "$ L $: number of layers in the network (by convention, input layer is not counted)  \n",
    " \n",
    "**Objectes:**  \n",
    "$ X \\in \\mathbb{R}^{n_x \\times m} $ is the input matrix  \n",
    "$ x^{(i)} \\in \\mathbb{R}^{n_x} $ is the $i^{th}$ example represented as a column vector  \n",
    "$ Y \\in \\mathbb{R}^{n_y \\times m}$ is the label matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
